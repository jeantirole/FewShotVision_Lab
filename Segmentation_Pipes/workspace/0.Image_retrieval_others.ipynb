{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#-- \n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import time\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/query/query_2.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_img_path = \"/disk3/eric/dataset/VISION_SOFS/WEAPON_4/query/query_2.png\"\n",
    "query_img = Image.open(query_img_path)\n",
    "plt.figure(figsize=(12,12))\n",
    "#plt.imshow(query_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAtAD0DASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDqvOhwCLgnPon+NRfa4gDxMw+gFSLAMD5xjsBSrBl0TI3EnAHfv/Q1ycq6m92QG7QNgQOfcv8A/Wp63QaPItkA9SSTU9lZC9meNW+WNsGQj5SfYjg0+70qdZJEt5IpWjwQFPUdwe4qXKCdikpMznurjcSkcaD/AHc/zqa0a/utqQszMT1QADHv+dWLOZEea7e0iUgbVO7hee+T6VX1PXWSBkgiiDK26Qbjlu3UY61LqLZIapvqV/Onh1GaxnaUXESrIVY5GD0wc094WZydxBPpTbW4fVNQk1Oe3kSRIggfqhGenH0/WtAhzyExgkYPH49CK1WxDWo17hkdkFg1ypTnBICnOOcVXntr3UY4WfUJrMxRENHFGB82cEKeo4q1C0h1m2gmZRbTBh0PL9QOK27h7e31CKRQyi4Uuqggcnggg9OxrGbakaR1WomkWVtFp1vGs0yxyjaokmJYseTxUV5fXUSrBaQkorGOS5fnkemKw9UmWIMbi5hT7J80aZwxf1GOCRg1o+Hr1LJ7i3nuI5Fl2srO3ByM8Z/l7VnKOnMx8zvZFDWdCKp+9DzQSKfMwmMkisSQWx0iNgrRFw6hX6DDbeeeeB+teiSQmSKaOC4QOcEZBJGR0Oa5HXtFnmmWa8kEdxM21Av3AB3JPTNEH0ZUn1MGw1a6OtxebO8luzbF3nCqMYAA6DHH611plRlDZUg9MVFafYI7Fle3hu5GARzGBkHHIB6+vtzUGi2slppUMMyBGUsAp5IXccA474xXVB3WxhJWLj7S6Psy0Tbk9jVy3hk1OA3PkI3nb1SN5MNHzgnOD0PasjziHkXHTjNNjlYAx7n2E5KbyFOfapqU+bVDhPl0G/8ACOaPpsKte3rXV+p3EK+XA9gM+/51cuTZSmKO20/NugIInO0sT0PrkZ71TEgjKQxxoiY6KuMU8yNhcMQOTRydZMHLsiV5b2Z23XHkwl8rFAuMegye3FPnl85wZ8yH/bGRVI3Lq6x5PzHrn1NOjdpSBnG0jJPOc5ppR6A+a12XPNAAwMAHjFHnIGIJbI96YloZU5k7k/d9OKkOngMT5nJ/2afMibM//9k=",
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=61x45>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/anaconda3/envs/trex/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/eric/anaconda3/envs/trex/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "images = os.listdir(\"/disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop\")\n",
    "os.environ[\"TORCH_HOME\"] = \"/disk3/eric/weight\"\n",
    "model = torchvision.models.resnet18(pretrained=True) #DEFAULT\n",
    "model.eval()\n",
    "root = \"/disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/\"\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256 , 256)) ,\n",
    "    transforms.ToTensor() ,\n",
    "    transforms.Normalize(mean = [0.485 , 0.456 , 0.406] , std = [0.229 , 0.224 , 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_7.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_8.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_1.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/query_2.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_11.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_10.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_12.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_13.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_14.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_6.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_3.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_15.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_0.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_9.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_5.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_4.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_2.png\n",
      "(17, 1000)\n"
     ]
    }
   ],
   "source": [
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model , input , output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "model.avgpool.register_forward_hook(get_activation(\"avgpool\"))\n",
    "\n",
    "#-- \n",
    "all_names = []\n",
    "all_heats = []\n",
    "all_vecs = []\n",
    "#-- \n",
    "\n",
    "with torch.no_grad():\n",
    "    for i , file in enumerate(images):\n",
    "            img = Image.open(os.path.join(root + file))\n",
    "            #print(img.size)\n",
    "            img = transform(img)\n",
    "            out = model(img[None , ...])\n",
    "            vec = activation[\"avgpool\"].numpy().squeeze()[None , ...]\n",
    "            \n",
    "            all_names.append(file)\n",
    "            all_heats.append(out)\n",
    "            all_vecs.append(vec)\n",
    "\n",
    "#---\n",
    "all_heats = np.vstack(all_heats)\n",
    "all_vecs = np.vstack(all_vecs)\n",
    "\n",
    "print(all_heats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target idx :  3\n",
      "target name :  query_2.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_0.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_1.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_5.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_9.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_7.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_12.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_13.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_2.png\n",
      "filename /disk3/eric/dataset/VISION_SOFS/WEAPON_4/trex_result_crop/cropped_box_3.png\n"
     ]
    }
   ],
   "source": [
    "idx = 3\n",
    "print(\"target idx : \", idx)\n",
    "print(\"target name : \", all_names[idx])\n",
    "\n",
    "target_vec = all_vecs[idx]\n",
    "\n",
    "top5 = cdist(target_vec[None , ...] , all_vecs,metric=\"cosine\").squeeze().argsort()[1:10]\n",
    "\n",
    "top_imgs =[]\n",
    "for i in range(9):\n",
    "    img_ = Image.open(os.path.join(root, all_names[top5[i]]))\n",
    "    top_imgs.append(img_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  2, 14, 13,  0,  6,  7, 16, 10])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 512)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_vecs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(all_vecs,axis=1,keepdims=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "emp_ = collections.defaultdict(list)\n",
    "\n",
    "\n",
    "for i,v in enumerate(all_vecs):\n",
    "    \n",
    "    norm_target_vec = target_vec / np.linalg.norm(target_vec)\n",
    "    normed_v = v / np.linalg.norm(v)\n",
    "    \n",
    "    cos_score = np.dot(norm_target_vec, normed_v)\n",
    "    emp_[i]=cos_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: 0.72050184,\n",
       "             1: 0.68794006,\n",
       "             2: 0.83276606,\n",
       "             3: 1.0,\n",
       "             4: 0.6660758,\n",
       "             5: 0.57657844,\n",
       "             6: 0.71034944,\n",
       "             7: 0.7099525,\n",
       "             8: 0.46781066,\n",
       "             9: 0.65075755,\n",
       "             10: 0.7026483,\n",
       "             11: 0.58457637,\n",
       "             12: 0.8450366,\n",
       "             13: 0.7311828,\n",
       "             14: 0.73944676,\n",
       "             15: 0.5502056,\n",
       "             16: 0.7089861})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = dict(sorted(emp_.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 1.0,\n",
       " 12: 0.8450366,\n",
       " 2: 0.83276606,\n",
       " 14: 0.73944676,\n",
       " 13: 0.7311828,\n",
       " 0: 0.72050184,\n",
       " 6: 0.71034944,\n",
       " 7: 0.7099525,\n",
       " 16: 0.7089861,\n",
       " 10: 0.7026483,\n",
       " 1: 0.68794006,\n",
       " 4: 0.6660758,\n",
       " 9: 0.65075755,\n",
       " 11: 0.58457637,\n",
       " 5: 0.57657844,\n",
       " 15: 0.5502056,\n",
       " 8: 0.46781066}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
